
Docker 
	Docker is one of the tools that used the idea of the isolated resources to 
	create a container that allows applications to be packaged with all the 
	dependencies installed and ran wherever we wanted.
	
	Docker can only run on Linux machines this means I cant install Dokcer directly on Windows or any other OS.
	If I want install Docker on windows then I need to run a Linux VM in windows on top that I need to run Docker.

Virtualization (VM)
	- VM is way of running virtual OS on top a host OS using a special software called Hyperviser.
	- VM directly shares the harware of the host OS. 

					VM 					vs 			Containerisation 
	1. Virtualization at hardware level  		1. Virtualization at OS level 
	2. Heavyweight - consume more host 			2. Lightweight
	   resources 	
	3. VM useses hypervisor 					3. containerisation tool is used 
	4. limited performace - Boot up time        4. Native performace - usualy boot 
		is more which is in minutes 			   fast in seconds.
	5. Cosumes more storage 					5. Shres OS storage means only uses 
												   required storage.
	6. Supports all OS 							6. Supports on Linux

host machine 
	This is the machine in which docker is running 

Docker installation

1. Update ubuntu 
	sudo apt update 

2. Install support packages for Docker
	sudo apt-get install -y ca-certificates curl gnupg lab-release

3. Need add key to download Docker 
	sudo mkdir -p /etc/apt/keyrings
	
	curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg	

4. Add docker packages to apt repository 
	echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

5. Install Docker 
	sudo apt-get update
 	sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin


Assignment: 1. Create docker hub account 

Login to your hub account 
	docker login 

Just try 
	STEP 1: create directory in /home/ubuntu/jenkins_home 

	Try to run Jenkins 

	docker run -it -d -p 8080:8080 -p 50000:50000 --name jeknis_master -v /home/ubuntu/jenkins_home:/var/jenkins_home jenkins/jenkins:lts

	docker logs -f jeknis_master

Docker images 
	1. To list images in the host machine 
		docker images
	
	2. To download image to host / local machine from docker hub
		docker pull <image_name>:<tag>
	
		docker pull ubuntu:18.04
	   If we won't provide/use any tag then docker will use the default tag "latest"	

	3. To delete docker image
		docker rmi <image_name>:<tag>
			 (OR)
		docker rmi <image_id>
		
	4. Delete multiple images 
		docker rmi <image_id1> <image_id2> ...

	5. Delete images forcefully even if there is a container related to it.
		docker rmi -f <image_id>
	
	6. To list only ids of images 
		docker images -q 
	
	7. To delete all local images 
		docker rmi $(docker images -q)
	

	To push a images to our own repository

		1. Create a tag which matches our repository name 
			image_name
				<username>/<repository_name>:<tag>

			docker tag <old_name>:<old_tag> <new_name>
			
		2. Login with docker account 
			docker login 

		3. Push the images to your own repository 
			

Docker containers 
	To list all docker running containers 
		docker ps 
		   (OR)
		docker container ls 

	To list all docker containers (running, exited, paused ....)
		docker ps -a
		   (OR)
		docker container ls -a
		
	To delete all docker containers except (running)
		docker rm <conatiner_name> 
		docker rm <container_id> 
	
	To stop all running container 
		docker stop $(docker ps -q)	
		
	To delete a running docker container 
		1. Forcefully delete 
			docker rm -f <container_id>

		2. Gracefully delete 
			2a. docker stop <container_id>
			2b. docker rm <container_id>
				(OR)
			To stop and delete running container in one-line
				docker rm $(docker stop <container_id>) 
						(OR)
				docker stop <container_id> | xargs -I{} docker rm "{}"
	
	To list all stopped containers 
		docker ps --filter "status=exited" -q

	To delete all the stopped containers 	
		docker rm $(docker ps --filter "status=exited" -q)

	To login / To get into a container 
		(To create a container docker run -it -d ubuntu /bin/bash)
		1. docker attach <container_id>
			To safely exit after attach (ctrl + (qp))
		2. docker exec -it /bin/bash 
			
	
Assignment: Try docker cp, docker pause, docker exec  

	docker cp 
		- This command is used to copy files and directories from host machine to container and 
		   container to host machine 
			From host machine to container 
				docker cp <host_path> <container_id>:<container_path> 

			From container to host machine 
				docker cp <container_id>:<container_path> <host_path>
	
	tty - we get output in console (stdstatus , stderror)

	docker exec 
		This command is used to run any command inside a running container and get the output.
	
To create a docker container 
	docker run -it -d -e <variable_name>=<variable_value> <image_name>:<tag> <command>
	    
	    Note: -i , interactive mode 
                  -t , tty terminal  		
		  -d , detached mode (creating container in background)
		  --name , User defined container name 
		  --rm, Once the container stops it will be deleted.	
		  -e, --env,  To create environment variable inside the container.  
		  -p, --publish <host_port>:<container_port>
		  --network, Network in which we want container to be created		
		( Image name at the end of the command always. 
		  If we want to add command for execution then command 
		  should be at end followed by image name)

Dockerfile 
	Dockerfile is used to create custom images by using any stock image or we can use any existing 
	docker image as base images.
	In Dockerfile we write some instruction to update any existing image.

	
	To create a image from Dockerfile 
		docker build -t <image_name>:<tag> <build_location>
		
	To build image from a custom docker file 
		docker build -t <image_name>:<tag> -f <dockerfile_path> <build_location>
	FROM 
	   - FROM is the first instruction in Dockerfile 
	   - At least one FROM should be there in a Dockerfile 
           - FROM is used to specify the base image (source image) on top of which we execute other 
	     instructions to update the base images to get our custom image.	
		
		FROM <image_name>:<tag>

	RUN 
	   - This is used to execute the supported command on the base image.
	   - We can have multiple (n number) RUN instructions in a single Dockerfile.
	   - Each RUN is an individual executor. Different RUN instructions never share the build context 
	     with each other.
	
		RUN <command>	
	
	WORKDIR 
		This is used to set the working directory for all the instruction which follows it in the 
		Dockerfile such as RUN, CMD, ENTRYPOINT ....
			WORKDIR <path> 
	
	COPY and ADD 
		COPY <source> <destination>
	   	  - COPY is used to copy files and directories from HOST machine to the image. When we 
	     	    create container out of this image it will also contains the files and directories 
	     	    which we copied.
	   	  - <source> location is always calculated in build context location (Not as of HOST machine)	
	   	  - <destination> is the path inside the container, If does not exists it will be created 
	     	    automatically. 	
	
		- Both COPY and ADD instruction is used to copy files and directories from host machine to
		  image which will be copied to container which is created from this image.
		- ADD instruction support 2 more extra formats 
		     1. If source is a downloadable link, ADD will download the file to the destination.
		     2. If it is compressed file, ADD will un-compresses it in the destination.	
	
	ENV
		- This is used ti set the environment variable inside container through image.
		- We can have multiple ENV instructions in a single Dockerfile.
			ENV <variable_name> <variable_value>
				(OR)
			ENV <variable_name>=<variable_value>

			Multiple variables 
			    ENV <variable_name1>=<variable_value1> <variable_name2>=<variable_value2>

		To create environment variable at RUN time.
		    we can create using -e or --env option with docker run command 
			docker run -e <variable_name>=<variable_value>
		    	NOTE: For multiple env variables we can use multiple -e option.	
				
		For loading lot of multiple env variables, the best way is using env file.
			STEP1: Add all the required env variable in a file (best name is .env)
			STEP2: Using --env-file <env_file_path> option with docker run command we can load at once
				docker run --env-file .env 	
	
	ARG 
		using this we can pass parameters to Dockerfile as user inputs 
			ARG <arg_var_name>=<default_value>

		docker build -t <image_name> --build-arg <arg_var_name>=<value> .

	CMD and ENTRYPOINT 
		SHELL format 
		   RUN ls -lrt 	
		   CMD ls -lrt 
		   ENTRYPOINT ls -lrt

		EXEC format 
			In list we represent the command and always the first event of list is command and other 
			elements are treated as options to it.
			 RUN ["ls","-lrt"] 	
		   	 CMD ["ls","-lrt"] 
		   	 ENTRYPOINT ["ls","-lrt"] 
			
	     - Both CMD & ENTRYPOINT are used to define the main execution command of container which will be 
	       created from the Dockerfile.
	     - If we have multiple CMD or ENTRYPOINT in the same Dockerfile only the latest one will be considered.
	     - If we have both CMD and ENTRYPOINT then ENTRYPOINT will get the highest priority over CMD and the 
	       CMD command will become as parameters to ENTRYPOINT.

	     Difference 
		- CMD command can be overridden at the runtime command (means with docker run command)
		- ENTRYPOINT command can not be overridden at the runtime command but what ever the command we pass 
		  at the runtime will become parameters to ENTRYPOINT command.
		
	Assignment: Can we override ENTRYPOINT at runtime ? (yes, How?)
	
	EXPOSE <port>	
		- used to expose a port to the internal docker network 
		- This makes the container port accessible by all the other containers in the 
		  same docker network. 

	IQ: 
		What is the difference b/w CMD and ENTRYPOINT ?	
		What is the difference b/w COPY and ADD ?
		What is the difference b/w EXPOSE and PUBLISH ?
		What is the difference b/w ENV and ARG ?

Dangling images 
	Dangling images are images which are created while executing Dockerfile instructions 
	in the image build process and these images have no relation with any other images or 
	containers even they will not have repository and tag name.
		To list only dangling images 
			docker images -f dangling=true 
		To delete dangling images 
			docker image prune 
				(OR)
			docker rmi $(docker images -f dangling=true -q)
		
docker system prune
	This will remove:
  	- all stopped containers
  	- all networks not used by at least one container
  	- all dangling images
 	- all dangling build cache

Docker Network
	Publish 
	   - Publish is used to bind the container port to any available host machine port.
	   - publish will automatically exposes port 
		
		publish = EXPOSE + port mapping to the host machine port 	
	     
	     To publish a port 
		docker run -p <host_port>:<container_port> .....	
	     
             -P publish_all 
		It binds all the exposed ports of the container to random host machine port
	     
	     Range of ports 
		Docker will search for available port in the range to bind to container port.
		  1) many to one: docker run -p 8080-8090:8080
		  2) many to many:  docker run -p 8080-8085:80-85
			always the total number of host range ports should be same as container 
			ports range 
			 			
            	
    	To list docker networks 
		docker network ls 
	Bridge 
	    - This is a private internal network created by docker on host machine by name 
	      docker0
	    - This is default network in docker which means when ever we create a container 
              without any network configuration it will be created in default bridge network.
	    - The default ip series is 172.17.0.1
	    - All the container in the same bridge network can communicate by default using 
	      the ip address of the containers.
		
	    Custom bridge network 
		To create custom bridge network 
			docker network create --drive bridge my_bride
		The advantage of using custom bridge is we can communicate between containers 
		using container name and also ip address as this will main an own ip table.

Assignment: How to communicate between containers which in different bridge network.

	2) HOST 
		This driver removes the extra layer of network isolation between docker and host 			
		machine.
		- Container created in this network are directly connected to host network.
		- They share the all the host network and got same configuration as host 
		  machine.
		- As we handle host network docker publish will not work with network driver.
			

	3) None
		- Containers are not attached to any network and they will not be having 
		  network configurations.
		- All the required network configuration should be done manually.

Docker volumes 
			
	Bind mounts 
		- We can mount host machine filesystem (files and directors) to a container.
		- If path inside container not present docker will automatically creates it.
		
		docker run -v <host_path>:<container_path>
	
	Volumes 
		- These are docker managed filesystem and we use docker commands to manage these 
		  volumes.
		- We can mount the volumes to multiple containers.
		- Volumes are easier to manage, backup or migrate than bind mounts.
		- Volumes supports multiple drivers which means we can mount.
		- Default location of docker volume /var/lib/docker/volumes 
		To create a docker volume 
			docker volume create <volume_name>
		To list docker volumes 
			docker volume ls
		To delete docker volume
			docker volume rm <volume_name>

		docker run -v <volume_name>:<container_path>


docker volume create \
    --driver local \
    --opt type=nfs \
    --opt o=addr=fs-0928767bcf17c9ed6.efs.ap-south-1.amazonaws.com,rw,nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 \
    --opt device=:/ efs 	

Docker container lifecycle - stages - statuses 
	Running - If main command is running without any error then container will get this state 
	Exited - If main command / process of the container failed due to some error 
	Paused - If we pause a container 
	Created - If container is created but the main command is not yet started.
	Dead - If Docker daemon fail to create / stop the container (Due to full RAM usage of 
	       host machine)
	Restarting - When we restart the main command of container.


Namespaces and cgroups
	- Docker uses linux namespaces to provide isolated workspace for processes called
	  conatainer
	- when a container is created, docker creates a set of namespaces for it and provides 
	  a layer of isolation for container.
	- Each container run in a different namespace 
	
	namespace (To list - lsns)
		cgroups 
			- Linux OS uses cgroups to manage the availale hardware resoruces such as 
			  cpu, RAM, Disk, I/O.
			- we can control tje access and also we can apply the limitations 

			To list - lscgroup	
		pid - namespace for managing processes (process isolation)
		user - namespace for non-root user on linux.
		uts - namespace for unix timesharing system which isolates kernel and version identifiers,
			  time bonding of process.
		ipc - (interprocess communication) namespace for managing the process communication.	  
		mnt - namespace for managing filesystem mounts.
		net - namespace for managing network interfaces.


Docker Architecture 

	Docker Daemon 
		- A background process that manages docker images, containers, network and volumes.
		- This Daemon constantly listens for docker API request and processes them.
	
	Docker REST API 
		- API which is used by applications to interact with the docker daemon. 
		
	Docker CLI 
		- It is a command line interface for interacting with docker daemon through
		  REST api.
	
	Docker Objects 
		- Images, Containers, Networks, Vloumes

Benefits of Docker 

	Flexible: 
		Complex applications cab be divided and containerised in small competents called 
		microservice. 
	
	Lightweight: 
		Containers share the machineâ€™s OS system kernel and therefore do not require 
		



Docker multistage build	

	How to optimise docker build process ?
	How to reduce the size of the docker image or container ? 

	After docker 1.6 version docker released this option.
	1. There are 2 problems with the normal build process 
			1. Size: challenge is to keep the image and its containers size as minimal as  		
			   possible.
			2. larger the surface area more the application is vulnerable to attacks. 
	
		- Multistage build allows us to define multiple FROM in same Dockerfile.
		- Dependency between multiple FROM is maintained by naming FROM using 
		  AS keyword and we can refer this name in another FROM.

				FROM <base_image> AS <STAGE_NAME>
				
		- Only the final FROM image is created leaving back all the other FROM.
		- Copy only the required files from the named FROM stage like below.
				FROM final_build
				COPY --from <STAGE_NAME> <src_named_stage> <dest>
	
	2. Always try to use the slim / alpine / stretch version of base image instead 
	   of using the fully loaded base image.


	
